{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction to LSTMs\n",
        "## What are LSTMs?\n",
        "\n",
        "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network (RNN) capable of learning long-term dependencies. They were introduced to address the vanishing gradient problem that can occur when training traditional RNNs.\n",
        "\n",
        "**Key Points:**\n",
        "- LSTMs are a special kind of RNN, capable of learning long-term dependencies.\n",
        "- They are widely used for sequential data, such as time series, speech, text, etc.\n"
      ],
      "metadata": {
        "id": "XOa_8pyluerJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applications of LSTMs:**\n",
        "- Time series prediction\n",
        "- Natural language processing\n",
        "- Speech recognition\n",
        "- Anomaly detection\n"
      ],
      "metadata": {
        "id": "aWWeOo5iuyQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Understanding LSTM Architecture\n",
        "\n",
        "LSTM Cell Structure\n",
        "The LSTM architecture consists of a memory cell, an input gate, a forget gate, and an output gate. These gates control the flow of information, protecting the network from vanishing or exploding gradient issues.\n",
        "\n",
        "1. Forget Gate: Decides what information to discard from the cell state.\n",
        "2. Input Gate: Decides which new information to add to the cell state.\n",
        "3. Output Gate: Decides what the next hidden state should be."
      ],
      "metadata": {
        "id": "CaS5ISFku29i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png"
      ],
      "metadata": {
        "id": "ajnRlj3qvK9T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "cVHMCEJ4uW3s",
        "outputId": "7d6cc67e-3f06-441f-b61d-952840f0a38f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "Image(url='https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTMs improve upon standard RNNs by introducing a more complex structure composed of memory cells and gating mechanisms. Here’s a breakdown of the LSTM architecture:\n",
        "\n",
        "\n",
        "1. Memory Cell:\n",
        "\n",
        "The core of an LSTM unit is the memory cell, which maintains information over long periods of time. Unlike the hidden state in a standard RNN, the memory cell has mechanisms to add or remove information, allowing it to capture and retain long-term dependencies.\n",
        "\n",
        "2. Gates\n",
        "\n",
        "LSTMs use gates to control the flow of information into and out of the memory cell. There are three main gates in an LSTM:\n",
        "\n",
        "Forget Gate (f_t):  This gate decides what portion of the memory cell's previous state should be forgotten. It takes the current input and the previous hidden state, and outputs a number between 0 and 1 for each value in the memory cell. A value of 1 means \"keep this information,\" while 0 means \"forget this information.\"\n",
        "\n",
        "Input Gate (i_t): This gate determines how much of the new information should be added to the memory cell. It has two parts: one that decides which values to update, and another that creates a vector of new candidate values.\n",
        "\n",
        "Output Gate (o_t): This gate controls what portion of the memory cell’s state should be output as the hidden state. It uses the memory cell state to compute the final hidden state.\n",
        "\n",
        "\n",
        "3. Memory Cell Update\n",
        "\n",
        "The memory cell state (C_t) is updated based on the input from the input gate and the previous memory cell state."
      ],
      "metadata": {
        "id": "Ua5aDi1kH8LS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Cell Computation Steps\n",
        "\n",
        "Forget Gate Calculation:\n",
        "\n",
        "Compute the forget gate’s activation using the previous hidden state and the current input.\n",
        "\n",
        "Input Gate Calculation:\n",
        "\n",
        "Compute the input gate’s activation and the candidate memory cell values.\n",
        "\n",
        "Memory Cell State Update:\n",
        "\n",
        "Update the memory cell state by combining the previous memory cell state (scaled by the forget gate) and the new candidate values (scaled by the input gate).\n",
        "\n",
        "Output Gate Calculation:\n",
        "\n",
        "Compute the output gate’s activation and determine the final hidden state using the updated memory cell state."
      ],
      "metadata": {
        "id": "_QK2Jv2YI9i6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applications of LSTMs in NLP\n",
        "LSTMs are widely used in NLP tasks, including:\n",
        "\n",
        "1. Language modeling\n",
        "2. Text generation\n",
        "3. Sentiment analysis\n",
        "4. Machine translation\n"
      ],
      "metadata": {
        "id": "mYABdxJ4viqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "x_t: Input at time step t\n",
        "\n",
        "h_{t-1}: Hidden state from the previous time step\n",
        "\n",
        "C_t: Updated memory cell state\n",
        "\n",
        "f_t: Forget gate output\n",
        "\n",
        "i_t: Input gate output\n",
        "\n",
        "o_t: Output gate output\n",
        "\n",
        "h_t: Hidden state output\n",
        "\n",
        "https://en.wikipedia.org/wiki/Long_short-term_memory"
      ],
      "metadata": {
        "id": "VDtP9o1sJTFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preparing Text Data for LSTM\n",
        "We'll use the Keras library to preprocess text data, which includes tokenization, sequencing, and padding."
      ],
      "metadata": {
        "id": "WCWnkVOyv-fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import re"
      ],
      "metadata": {
        "id": "uD1gukSPu_bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FkoZkT0wFix",
        "outputId": "5a193c78-93b4-42d5-e8ce-527512c0072d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78c010b24d10>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "A financial transaction is an agreement, or communication, between a buyer and seller to exchange goods, services, or assets for payment. Any transaction involves a change in the status of the finances of two or more businesses or individuals. A financial transaction always involves one or more financial asset, most commonly money or another valuable item such as gold or silver.\n",
        "\n",
        "There are many types of financial transactions. The most common type, purchases, occur when a good, service, or other commodity is sold to a consumer in exchange for money. Most purchases are made with cash payments, including physical currency, debit cards, or cheques. The other main form of payment is credit, which gives immediate access to funds in exchange for repayment at a later date.\n",
        "\n",
        "History\n",
        "\n",
        "Silver coin of the Maurya Empire, from the 3rd century BC\n",
        "\n",
        "There is no evidence to support the theory that ancient civilizations worked on systems of barter. Instead, most historians believe that ancient cultures worked on principles of gift economy and debt. In a gift economy, valuables are given without any formal declaration of repayment, often thought to be a form of reciprocal altruism. Official systems of credit and debt were first created around 1800 BCE by the Babylonians, who established the first formal interest rate limits with the Code of Hammurabi.\n",
        "\n",
        "Many cultures around the world began using commodity money—objects whose value comes from their intrinsic value. These often included gold or silver coins, along with non-metal objects such as cowrie shells, beaver pelts, and dried corn. Between 1000 BCE and the first millennium CE, coinage became increasingly common throughout Europe and Asia. In England, banknotes were introduced starting in the 17th century. Each note promised to pay the bearer the value in gold upon demand—this is called a gold standard. In the 20th century, many countries gradually phased out the gold standard in favour of fiat money—money that is not backed by any commodity.\n",
        "\n",
        "Since the start of the 21st century, online banking has become much more widespread. By 2001, tens of millions of people were doing their banking on the internet. By 2012, between 46 and 82 percent of all transactions were done electronically. Digital currencies, currency that is stored on electronic systems, have gained popularity. Bitcoin, invented in 2009, reached a cap of over US$1 trillion in 2021. One of the downsides of cryptocurrencies is that since they are not tethered to any tangible assets, their price can fluctuate wildly, sometimes by 20% or more in a single day.\n",
        "\n",
        "Types of transactions\n",
        "\n",
        "Purchases can be made through the use of physical currency, such as cash.\n",
        "\n",
        "Cash transactions\n",
        "A cash transaction is any transaction where money is exchanged for a good, service, or other commodity. Cash transactions can refer to items bought with physical money, such as coins or cash, or with a debit card. These differ from credit transactions because the money is immediately taken from the buyer and given to the seller.\n",
        "\n",
        "Credit transactions\n",
        "Transactions that use credit involve a deferred payment for the goods or services rendered. When something is bought using credit, it gives the seller an asset (the payment at a later date) and gives the buyer a liability (the amount that must be paid at a later date). Credit cards are an example of when credit is used, where the card issuer (usually a bank) gives the customer a line of credit with which they can make purchases. The liabilities the customer accrues with the card are usually paid off at a set date, and any unpaid liabilities create interest for the issuer.\n",
        "\n",
        "Loans and mortgages are examples of credit. The lender agrees to give out a lump sum (the \"principal\") to the borrower, who pays back the loaned amount over a set period of time (called a \"term\"). The lender usually charges an additional percentage on top of the initial amount borrowed, called the \"interest rate\". Mortgages are similar to loans, but are usually for a larger amount of money and over a longer term, often for buying real estate. Mortgages are almost always secured by collateral, most commonly the real estate they are being used to purchase. If the borrower fails to make the necessary payments on the mortgage, the lender has the right to claim and sell the property in a process known as foreclosure.\n",
        "\n",
        "Internal and external transactions\n",
        "External transactions are any business transactions that involve more than one party. For example, a company buying inventory from a supplier would be considered external. All cash and credit transactions are external, since they affect the finances of more than one person or group. On the other hand, internal transactions only affect one business. Shifting goods between different departments in a business is an internal transaction, since it does not change the overall finances of the company.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "O2vBnM4XxktQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove references like [1], [2], etc.\n",
        "    text = re.sub(r'\\s+', ' ', text)     # Remove extra whitespace\n",
        "    text = text.replace('\\n', ' ')       # Remove new lines\n",
        "    text = text.lower()                  # Convert to lowercase\n",
        "    return text\n",
        "\n",
        "cleaned_text = clean_text(text)"
      ],
      "metadata": {
        "id": "OUugWB3Dxos0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cleaned Text:\")\n",
        "print(cleaned_text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMf8R7Jdxs_u",
        "outputId": "3bc6f5fa-21e9-4b45-cdbb-ecd5fcde6a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text:\n",
            " a financial transaction is an agreement, or communication, between a buyer and seller to exchange goods, services, or assets for payment. any transaction involves a change in the status of the finances of two or more businesses or individuals. a financial transaction always involves one or more financial asset, most commonly money or another valuable item such as gold or silver. there are many types of financial transactions. the most common type, purchases, occur when a good, service, or other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharTokenizer:\n",
        "    def __init__(self):\n",
        "        self.char2idx = {}\n",
        "        self.idx2char = {}\n",
        "\n",
        "    def fit(self, text):\n",
        "        unique_chars = sorted(set(text))\n",
        "        self.char2idx = {c: i for i, c in enumerate(unique_chars)}\n",
        "        self.idx2char = {i: c for i, c in enumerate(unique_chars)}\n",
        "\n",
        "    def texts_to_sequences(self, text):\n",
        "        return [self.char2idx[char] for char in text]\n",
        "\n",
        "    def sequences_to_texts(self, sequence):\n",
        "        return [self.idx2char[idx] for idx in sequence]"
      ],
      "metadata": {
        "id": "b40Yxwn1xw2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = CharTokenizer()\n",
        "tokenizer.fit(cleaned_text)"
      ],
      "metadata": {
        "id": "7010IR3Fx1Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to sequences of integers\n",
        "sequences = tokenizer.texts_to_sequences(cleaned_text)"
      ],
      "metadata": {
        "id": "hGG1o7lox8Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input-output pairs\n",
        "def create_dataset(sequences, step):\n",
        "    X, y = [], []\n",
        "    for i in range(0, len(sequences) - step):\n",
        "        X.append(sequences[i:i + step])\n",
        "        y.append(sequences[i + step])\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "8jN1J0IYx_vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "step = 40  # Length of each input sequence\n",
        "X, y = create_dataset(sequences, step)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\n",
        "y = torch.tensor(y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "8G3MJpSByDv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PyTorch Dataset and DataLoader\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "VkQmDlNQyJBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset(X, y)\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "imutrjhGyPJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        output = self.fc(h_n.squeeze(0))\n",
        "        return output"
      ],
      "metadata": {
        "id": "LoChWP1SyTU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss function, and optimizer\n",
        "input_size = 1\n",
        "hidden_size = 128\n",
        "output_size = len(tokenizer.char2idx)\n",
        "model = LSTMModel(input_size, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "8BusouaWyXwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    for inputs, targets in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(dataloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHKZJWHvyby0",
        "outputId": "9f3147a4-a65a-4acf-966a-856de46001e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 3.188887671420449\n",
            "Epoch 2/20, Loss: 2.87601007285871\n",
            "Epoch 3/20, Loss: 2.8111952919709053\n",
            "Epoch 4/20, Loss: 2.7771467472377576\n",
            "Epoch 5/20, Loss: 2.7516434318140934\n",
            "Epoch 6/20, Loss: 2.730541229248047\n",
            "Epoch 7/20, Loss: 2.7155682224976387\n",
            "Epoch 8/20, Loss: 2.7009178713748327\n",
            "Epoch 9/20, Loss: 2.6802993071706673\n",
            "Epoch 10/20, Loss: 2.6647705906315853\n",
            "Epoch 11/20, Loss: 2.647393929330926\n",
            "Epoch 12/20, Loss: 2.6305983443009224\n",
            "Epoch 13/20, Loss: 2.6165057608955786\n",
            "Epoch 14/20, Loss: 2.604543836493241\n",
            "Epoch 15/20, Loss: 2.5922984449486983\n",
            "Epoch 16/20, Loss: 2.5720849790071187\n",
            "Epoch 17/20, Loss: 2.557548849206222\n",
            "Epoch 18/20, Loss: 2.5470267847964636\n",
            "Epoch 19/20, Loss: 2.5357374517541182\n",
            "Epoch 20/20, Loss: 2.5183053518596448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path where the model will be saved\n",
        "model_path = \"lstm_text_generation_model.pth\"\n",
        "\n",
        "# Save the model's state dictionary\n",
        "torch.save(model.state_dict(), model_path)\n",
        "\n",
        "print(f\"Model saved to {model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_SfcOOizeq4",
        "outputId": "9e947da3-3586-4d77-d8c9-57b9e3b37b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to lstm_text_generation_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate text\n",
        "def generate_text(model, tokenizer, seed_text, length=100):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    input_sequence = tokenizer.texts_to_sequences(seed_text)\n",
        "    input_sequence = torch.tensor(input_sequence, dtype=torch.float32).unsqueeze(0).unsqueeze(-1)\n",
        "    result = seed_text\n",
        "    for _ in range(length):\n",
        "        output = model(input_sequence)\n",
        "        predicted_index = torch.argmax(output, dim=1).item()\n",
        "        predicted_char = tokenizer.idx2char[predicted_index]\n",
        "        result += predicted_char\n",
        "        input_sequence = torch.cat([input_sequence[:, 1:], torch.tensor([[[predicted_index]]], dtype=torch.float32)], dim=1)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "wB3ApZGWyfE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the seed text and generate text\n",
        "seed_text = \"a financial transaction is an agreement\"\n",
        "generated_text = generate_text(model, tokenizer, seed_text, length=100)\n",
        "\n",
        "# Print the generated text\n",
        "print(\"Generated Text:\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9JEotU9yoel",
        "outputId": "27dfa096-4333-4e10-af00-97b348cdb20d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "a financial transaction is an agreement a coren th the the the the the the the the the the the the the the the the the the the the the the \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PaWfzqGFzR_r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}